{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyf-IzhcWXV7",
        "outputId": "f37c237d-d9e5-4573-945d-9f82c69e5d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LangPathModel'...\n",
            "remote: Enumerating objects: 512, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 512 (delta 116), reused 177 (delta 51), pack-reused 266 (from 1)\u001b[K\n",
            "Receiving objects: 100% (512/512), 165.32 MiB | 30.84 MiB/s, done.\n",
            "Resolving deltas: 100% (250/250), done.\n"
          ]
        }
      ],
      "source": [
        "# get the model from github\n",
        "!git clone https://github.com/AntonioSkara132/LangPathModel.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initialization**"
      ],
      "metadata": {
        "id": "RF_NI_ZcWp-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "%matplotlib inline\n",
        "!apt-get -y update && apt-get -y install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1TMLSFEWeTO",
        "outputId": "90162780-d29e-4b73-d1ba-3540f866439e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 95 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Dataset Creation**"
      ],
      "metadata": {
        "id": "ZhpxORLUW3Kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/Tonio123/CaptyShapes -b main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvA3WloX5zob",
        "outputId": "f3f28aae-2b39-436e-e6b0-0991a5be6403"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CaptyShapes'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 4.14 KiB | 1.38 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Data visualization**"
      ],
      "metadata": {
        "id": "2ALfgw0ufkAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/LangPathModel/data/data_visualization.py /content/CaptyShapes/all_shapes.pt\n",
        "display(Image(\"visualization.png\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "fYvSvol0acZ-",
        "outputId": "43ff4abf-a342-49ed-970a-b32a46a425ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/LangPathModel/data/data_visualization.py': [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: 'visualization.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'visualization.png'"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: 'visualization.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'visualization.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Training**"
      ],
      "metadata": {
        "id": "w49FeTVxE54r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python LangPathModel/src/training.py \\\n",
        "  --niter 100 \\\n",
        "  --start_lr 0.001 \\\n",
        "  --lr_step 10 \\\n",
        "  --weight_decay 1e-5 \\\n",
        "  --d_model 64 \\\n",
        "  --num_heads 8 \\\n",
        "  --num_decoder_layers 2 \\\n",
        "  --dropout 0.2 \\\n",
        "  --gamma 0.1 \\\n",
        "  --batch_size 500 \\\n",
        "  --dataset_path /content/CaptyShapes/small_dataset.pt \\\n",
        "  --output_path /new_model.pth\n",
        "#for testing use small_dataset instead of all shapes.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpaKgH_3BXz8",
        "outputId": "0594156e-9755-47da-e363-0001c2f4edfc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-25 23:04:12.743763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-25 23:04:12.761786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748214252.784267   10328 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748214252.790994   10328 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-25 23:04:12.812496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "input_embedding.weight: cuda:0\n",
            "input_embedding.bias: cuda:0\n",
            "text_encoder.bert.embeddings.word_embeddings.weight: cuda:0\n",
            "text_encoder.bert.embeddings.position_embeddings.weight: cuda:0\n",
            "text_encoder.bert.embeddings.token_type_embeddings.weight: cuda:0\n",
            "text_encoder.bert.embeddings.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.embeddings.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.0.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.1.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.2.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.3.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.4.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.5.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.6.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.7.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.8.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.9.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.10.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.self.query.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.self.query.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.self.key.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.self.key.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.self.value.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.self.value.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.intermediate.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.intermediate.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.output.dense.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.output.dense.bias: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.output.LayerNorm.weight: cuda:0\n",
            "text_encoder.bert.encoder.layer.11.output.LayerNorm.bias: cuda:0\n",
            "text_encoder.bert.pooler.dense.weight: cuda:0\n",
            "text_encoder.bert.pooler.dense.bias: cuda:0\n",
            "text_encoder.projection.weight: cuda:0\n",
            "decoder.layers.0.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.0.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.0.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.0.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.0.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.0.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.0.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.0.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.0.linear1.weight: cuda:0\n",
            "decoder.layers.0.linear1.bias: cuda:0\n",
            "decoder.layers.0.linear2.weight: cuda:0\n",
            "decoder.layers.0.linear2.bias: cuda:0\n",
            "decoder.layers.0.norm1.weight: cuda:0\n",
            "decoder.layers.0.norm1.bias: cuda:0\n",
            "decoder.layers.0.norm2.weight: cuda:0\n",
            "decoder.layers.0.norm2.bias: cuda:0\n",
            "decoder.layers.0.norm3.weight: cuda:0\n",
            "decoder.layers.0.norm3.bias: cuda:0\n",
            "decoder.layers.1.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.1.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.1.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.1.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.1.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.1.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.1.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.1.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.1.linear1.weight: cuda:0\n",
            "decoder.layers.1.linear1.bias: cuda:0\n",
            "decoder.layers.1.linear2.weight: cuda:0\n",
            "decoder.layers.1.linear2.bias: cuda:0\n",
            "decoder.layers.1.norm1.weight: cuda:0\n",
            "decoder.layers.1.norm1.bias: cuda:0\n",
            "decoder.layers.1.norm2.weight: cuda:0\n",
            "decoder.layers.1.norm2.bias: cuda:0\n",
            "decoder.layers.1.norm3.weight: cuda:0\n",
            "decoder.layers.1.norm3.bias: cuda:0\n",
            "decoder.layers.2.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.2.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.2.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.2.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.2.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.2.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.2.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.2.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.2.linear1.weight: cuda:0\n",
            "decoder.layers.2.linear1.bias: cuda:0\n",
            "decoder.layers.2.linear2.weight: cuda:0\n",
            "decoder.layers.2.linear2.bias: cuda:0\n",
            "decoder.layers.2.norm1.weight: cuda:0\n",
            "decoder.layers.2.norm1.bias: cuda:0\n",
            "decoder.layers.2.norm2.weight: cuda:0\n",
            "decoder.layers.2.norm2.bias: cuda:0\n",
            "decoder.layers.2.norm3.weight: cuda:0\n",
            "decoder.layers.2.norm3.bias: cuda:0\n",
            "decoder.layers.3.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.3.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.3.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.3.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.3.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.3.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.3.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.3.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.3.linear1.weight: cuda:0\n",
            "decoder.layers.3.linear1.bias: cuda:0\n",
            "decoder.layers.3.linear2.weight: cuda:0\n",
            "decoder.layers.3.linear2.bias: cuda:0\n",
            "decoder.layers.3.norm1.weight: cuda:0\n",
            "decoder.layers.3.norm1.bias: cuda:0\n",
            "decoder.layers.3.norm2.weight: cuda:0\n",
            "decoder.layers.3.norm2.bias: cuda:0\n",
            "decoder.layers.3.norm3.weight: cuda:0\n",
            "decoder.layers.3.norm3.bias: cuda:0\n",
            "decoder.layers.4.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.4.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.4.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.4.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.4.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.4.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.4.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.4.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.4.linear1.weight: cuda:0\n",
            "decoder.layers.4.linear1.bias: cuda:0\n",
            "decoder.layers.4.linear2.weight: cuda:0\n",
            "decoder.layers.4.linear2.bias: cuda:0\n",
            "decoder.layers.4.norm1.weight: cuda:0\n",
            "decoder.layers.4.norm1.bias: cuda:0\n",
            "decoder.layers.4.norm2.weight: cuda:0\n",
            "decoder.layers.4.norm2.bias: cuda:0\n",
            "decoder.layers.4.norm3.weight: cuda:0\n",
            "decoder.layers.4.norm3.bias: cuda:0\n",
            "output_layer.weight: cuda:0\n",
            "output_layer.bias: cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "[23:04:18] Epoch 001/100 | Loss:   1.9161 | Time:   0.62s\n",
            "[23:04:19] Epoch 002/100 | Loss:   0.7761 | Time:   0.24s\n",
            "[23:04:19] Epoch 003/100 | Loss:   0.3972 | Time:   0.24s\n",
            "[23:04:19] Epoch 004/100 | Loss:   0.5339 | Time:   0.24s\n",
            "[23:04:19] Epoch 005/100 | Loss:   0.3568 | Time:   0.25s\n",
            "[23:04:20] Epoch 006/100 | Loss:   0.2613 | Time:   0.24s\n",
            "[23:04:20] Epoch 007/100 | Loss:   0.3161 | Time:   0.24s\n",
            "[23:04:20] Epoch 008/100 | Loss:   0.3223 | Time:   0.24s\n",
            "[23:04:20] Epoch 009/100 | Loss:   0.2954 | Time:   0.24s\n",
            "[23:04:21] Epoch 010/100 | Loss:   0.2538 | Time:   0.25s\n",
            "  â†³ saved checkpoint to /content/LangPathModel/checkpoints/model_state_epoch_010.pth\n",
            "[23:04:22] Epoch 011/100 | Loss:   0.2487 | Time:   0.25s\n",
            "[23:04:22] Epoch 012/100 | Loss:   0.2468 | Time:   0.25s\n",
            "[23:04:22] Epoch 013/100 | Loss:   0.2448 | Time:   0.25s\n",
            "[23:04:22] Epoch 014/100 | Loss:   0.2548 | Time:   0.24s\n",
            "[23:04:23] Epoch 015/100 | Loss:   0.2435 | Time:   0.24s\n",
            "[23:04:23] Epoch 016/100 | Loss:   0.2426 | Time:   0.24s\n",
            "[23:04:23] Epoch 017/100 | Loss:   0.2377 | Time:   0.24s\n",
            "[23:04:23] Epoch 018/100 | Loss:   0.2250 | Time:   0.25s\n",
            "[23:04:24] Epoch 019/100 | Loss:   0.2223 | Time:   0.25s\n",
            "[23:04:24] Epoch 020/100 | Loss:   0.2301 | Time:   0.24s\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 944, in save\n",
            "    _save(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1190, in _save\n",
            "    pickler.dump(obj)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1186, in persistent_id\n",
            "    def persistent_id(self, obj):\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/LangPathModel/src/training.py\", line 83, in <module>\n",
            "    main()\n",
            "  File \"/content/LangPathModel/src/training.py\", line 65, in main\n",
            "    train(\n",
            "  File \"/content/LangPathModel/src/train.py\", line 93, in train\n",
            "    torch.save(model.state_dict(), ckpt_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 943, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 784, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Evaluate**"
      ],
      "metadata": {
        "id": "dIGxKGKKkJ_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doesnt work\n",
        "# 2. run (GIF output; no external ffmpeg needed)\n",
        "!python src/evaluate_model.py \\\n",
        "        --model_path trained_models/best_model.pth \\\n",
        "        --text \"bottom circle\" \\\n",
        "        --save out.gif      # or omit --save to see inline\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GL7iLJKAJ3S",
        "outputId": "75b81990-2b59-483b-ef1e-ea6dd7b23697"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-25 23:17:11.816130: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-25 23:17:11.834040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748215031.855762   15852 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748215031.862296   15852 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-25 23:17:11.883992: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:matplotlib.animation:MovieWriter stderr:\n",
            "[NULL @ 0x5c23703808c0] Unable to find a suitable output format for 'False'\n",
            "False: Invalid argument\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/animation.py\", line 224, in saving\n",
            "    yield self\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/animation.py\", line 1109, in save\n",
            "    anim._init_draw()  # Clear the initial frame\n",
            "    ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/animation.py\", line 1770, in _init_draw\n",
            "    self._draw_frame(frame_data)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/animation.py\", line 1789, in _draw_frame\n",
            "    self._drawn_artists = self._func(framedata, *self._args)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/LangPathModel/src/evaluate_model.py\", line 75, in update\n",
            "    pred_next = model(text=txt,\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/LangPathModel/src/nn.py\", line 56, in forward\n",
            "    out = self.decoder(emb_tgt, memory=emb_text, tgt_mask=tgt_mask, tgt_key_padding_mask = path_mask[:, :-1])\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 613, in forward\n",
            "    output = mod(\n",
            "             ^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1108, in forward\n",
            "    x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1128, in _sa_block\n",
            "    x = self.self_attn(\n",
            "        ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1308, in forward\n",
            "    merged_mask, mask_type = self.merge_masks(\n",
            "                             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1441, in merge_masks\n",
            "    key_padding_mask_expanded = key_padding_mask.view(\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: shape '[1, 1, 1, 1]' is invalid for input of size 0\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/LangPathModel/src/evaluate_model.py\", line 140, in <module>\n",
            "    generate_animation(model=model,\n",
            "  File \"/content/LangPathModel/src/evaluate_model.py\", line 102, in generate_animation\n",
            "    ani.save(save_path, writer=writer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/animation.py\", line 1098, in save\n",
            "    with (writer.saving(self._fig, filename, dpi),\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/animation.py\", line 226, in saving\n",
            "    self.finish()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/animation.py\", line 341, in finish\n",
            "    raise subprocess.CalledProcessError(\n",
            "subprocess.CalledProcessError: Command '['ffmpeg', '-f', 'rawvideo', '-vcodec', 'rawvideo', '-s', '900x900', '-pix_fmt', 'rgba', '-framerate', '10', '-loglevel', 'error', '-i', 'pipe:', '-vcodec', 'libx264', '-y', 'False']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Add velocities and export it as csv**"
      ],
      "metadata": {
        "id": "Hv6SjAPpkVM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to do\n",
        "#vels = path2vels(path)\n",
        "#path = [path, vels]\n",
        "#save to csv"
      ],
      "metadata": {
        "id": "5zRc8BppkcNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}