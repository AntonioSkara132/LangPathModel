{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNdFZvC/aj5i3+x+ApahLCh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c53705e166a422281340d3e8e4b590b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d97e1fe03e1447699bd33859393b9793",
              "IPY_MODEL_57ae93e9579843d3a148497040c5bf29",
              "IPY_MODEL_ac7b2d823b6145cd886f58a811aa85c9"
            ],
            "layout": "IPY_MODEL_11c071412ac742ffb2b6108bcc5d476b"
          }
        },
        "d97e1fe03e1447699bd33859393b9793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dd3b7bc6c014396985ce0d904cc54f4",
            "placeholder": "​",
            "style": "IPY_MODEL_bfc9297fe3b24910bb3ff78f8d219cb1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "57ae93e9579843d3a148497040c5bf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdd2dcac413343b3b8a4aecbe9438fe3",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdcd947c5ade4939b5800364711c3ed2",
            "value": 48
          }
        },
        "ac7b2d823b6145cd886f58a811aa85c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccf795e9c8d495a8c34872752d660c2",
            "placeholder": "​",
            "style": "IPY_MODEL_102104b556c24719a07e9a6349d06d31",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.97kB/s]"
          }
        },
        "11c071412ac742ffb2b6108bcc5d476b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dd3b7bc6c014396985ce0d904cc54f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc9297fe3b24910bb3ff78f8d219cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdd2dcac413343b3b8a4aecbe9438fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdcd947c5ade4939b5800364711c3ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ccf795e9c8d495a8c34872752d660c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102104b556c24719a07e9a6349d06d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88c439241cd840f28c71e8674ab31799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3648facc0eef4c11b5f74f73dec46f86",
              "IPY_MODEL_c521863fc6334d9384833b832479223d",
              "IPY_MODEL_d5adddde7d6d4358835889a61a27c627"
            ],
            "layout": "IPY_MODEL_982c8f62966f4ae0a534678cb0cd668f"
          }
        },
        "3648facc0eef4c11b5f74f73dec46f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0197564f151f466691c1e0855b97ba86",
            "placeholder": "​",
            "style": "IPY_MODEL_e68d2542e8c5479b8bc516803bf94c43",
            "value": "config.json: 100%"
          }
        },
        "c521863fc6334d9384833b832479223d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29605b09341485c8b3a2065f9ff7f78",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47e6f5bdaae24d43999a76fc0e75a2d8",
            "value": 570
          }
        },
        "d5adddde7d6d4358835889a61a27c627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77fe80d7a41542119173b4b2478c15ba",
            "placeholder": "​",
            "style": "IPY_MODEL_6f811ddd15ec4210bd1c58c2788b42e0",
            "value": " 570/570 [00:00&lt;00:00, 15.9kB/s]"
          }
        },
        "982c8f62966f4ae0a534678cb0cd668f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0197564f151f466691c1e0855b97ba86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68d2542e8c5479b8bc516803bf94c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b29605b09341485c8b3a2065f9ff7f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e6f5bdaae24d43999a76fc0e75a2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77fe80d7a41542119173b4b2478c15ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f811ddd15ec4210bd1c58c2788b42e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96e2a31c9de0457d91d288a0b0d26073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bcd0111586e4302ab9e3a8acd8c1fef",
              "IPY_MODEL_abfeaaf6d6704ed78f451c561f9d24a0",
              "IPY_MODEL_ee026af0b56a4702b742eef4d81ac12c"
            ],
            "layout": "IPY_MODEL_02c09cb0b2644188982be38713009122"
          }
        },
        "3bcd0111586e4302ab9e3a8acd8c1fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a20798964d243da927d462671b0db59",
            "placeholder": "​",
            "style": "IPY_MODEL_5f8ed29137bf40e280d6767150643f47",
            "value": "vocab.txt: 100%"
          }
        },
        "abfeaaf6d6704ed78f451c561f9d24a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f47fc713674c3e9080e3c84b4b9037",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8040f27af0fa44ab8134f54fcf11d1af",
            "value": 231508
          }
        },
        "ee026af0b56a4702b742eef4d81ac12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0872c6f8e3c427c8bad79a701488647",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c3e69758d94656b580d94b864738ff",
            "value": " 232k/232k [00:00&lt;00:00, 541kB/s]"
          }
        },
        "02c09cb0b2644188982be38713009122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a20798964d243da927d462671b0db59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8ed29137bf40e280d6767150643f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2f47fc713674c3e9080e3c84b4b9037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8040f27af0fa44ab8134f54fcf11d1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0872c6f8e3c427c8bad79a701488647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c3e69758d94656b580d94b864738ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4d08d78e96f4b58b682bb455a954026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1c4794bc822423f9984ec3ddf665fa1",
              "IPY_MODEL_5a336dd0ae184e5d998cd4c69ec5e9de",
              "IPY_MODEL_a5dbd9b978844b4eaafb6105dca30615"
            ],
            "layout": "IPY_MODEL_f0aec8678c2d4a98939bc8548afa3549"
          }
        },
        "a1c4794bc822423f9984ec3ddf665fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484a49e795cf424fa55268f03dd0a978",
            "placeholder": "​",
            "style": "IPY_MODEL_388a522993e748b8bdf9a26a8f26daf5",
            "value": "tokenizer.json: 100%"
          }
        },
        "5a336dd0ae184e5d998cd4c69ec5e9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3fbd0645374345b595a2bba6a27f44",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8cf0c7839cc4c4db78526e093ec0eb0",
            "value": 466062
          }
        },
        "a5dbd9b978844b4eaafb6105dca30615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e94679bb62b470fab72517f10b21a61",
            "placeholder": "​",
            "style": "IPY_MODEL_a11df72c58cb4fd2b3969fc6727da6f7",
            "value": " 466k/466k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "f0aec8678c2d4a98939bc8548afa3549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484a49e795cf424fa55268f03dd0a978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388a522993e748b8bdf9a26a8f26daf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f3fbd0645374345b595a2bba6a27f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cf0c7839cc4c4db78526e093ec0eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e94679bb62b470fab72517f10b21a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11df72c58cb4fd2b3969fc6727da6f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonioSkara132/LangPathModel/blob/main/colab_src/notebook1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvoS23NghaEP",
        "outputId": "78704832-d9f7-40b4-bcd7-d8812315ffd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LangPathModel'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 84 (delta 28), reused 51 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (84/84), 12.51 MiB | 15.54 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AntonioSkara132/LangPathModel.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "\n",
        "class CirclePathDataset(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        # Load the data from the .pt file\n",
        "        self.data = torch.load(file_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the path tensor and the text for the given index\n",
        "        path_tensor = self.data[idx]['path']\n",
        "        text = self.data[idx]['text']\n",
        "        return path_tensor, text\n",
        "\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Unzip the batch into paths and texts\n",
        "    paths, texts = zip(*batch)\n",
        "\n",
        "    # Pad the paths (ensure they're all the same length)\n",
        "    padded_paths = pad_sequence(paths, batch_first=True, padding_value=0)  # Padding value can be set to 0\n",
        "\n",
        "    encoded = tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    return padded_paths, encoded\n",
        "\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CirclePathDataset(\"/content/LangPathModel/data/circle_in_the middle.pt\")\n",
        "\n",
        "# Create a DataLoader with the custom collate_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "0c53705e166a422281340d3e8e4b590b",
            "d97e1fe03e1447699bd33859393b9793",
            "57ae93e9579843d3a148497040c5bf29",
            "ac7b2d823b6145cd886f58a811aa85c9",
            "11c071412ac742ffb2b6108bcc5d476b",
            "9dd3b7bc6c014396985ce0d904cc54f4",
            "bfc9297fe3b24910bb3ff78f8d219cb1",
            "fdd2dcac413343b3b8a4aecbe9438fe3",
            "fdcd947c5ade4939b5800364711c3ed2",
            "5ccf795e9c8d495a8c34872752d660c2",
            "102104b556c24719a07e9a6349d06d31",
            "88c439241cd840f28c71e8674ab31799",
            "3648facc0eef4c11b5f74f73dec46f86",
            "c521863fc6334d9384833b832479223d",
            "d5adddde7d6d4358835889a61a27c627",
            "982c8f62966f4ae0a534678cb0cd668f",
            "0197564f151f466691c1e0855b97ba86",
            "e68d2542e8c5479b8bc516803bf94c43",
            "b29605b09341485c8b3a2065f9ff7f78",
            "47e6f5bdaae24d43999a76fc0e75a2d8",
            "77fe80d7a41542119173b4b2478c15ba",
            "6f811ddd15ec4210bd1c58c2788b42e0",
            "96e2a31c9de0457d91d288a0b0d26073",
            "3bcd0111586e4302ab9e3a8acd8c1fef",
            "abfeaaf6d6704ed78f451c561f9d24a0",
            "ee026af0b56a4702b742eef4d81ac12c",
            "02c09cb0b2644188982be38713009122",
            "4a20798964d243da927d462671b0db59",
            "5f8ed29137bf40e280d6767150643f47",
            "a2f47fc713674c3e9080e3c84b4b9037",
            "8040f27af0fa44ab8134f54fcf11d1af",
            "a0872c6f8e3c427c8bad79a701488647",
            "d3c3e69758d94656b580d94b864738ff",
            "a4d08d78e96f4b58b682bb455a954026",
            "a1c4794bc822423f9984ec3ddf665fa1",
            "5a336dd0ae184e5d998cd4c69ec5e9de",
            "a5dbd9b978844b4eaafb6105dca30615",
            "f0aec8678c2d4a98939bc8548afa3549",
            "484a49e795cf424fa55268f03dd0a978",
            "388a522993e748b8bdf9a26a8f26daf5",
            "7f3fbd0645374345b595a2bba6a27f44",
            "a8cf0c7839cc4c4db78526e093ec0eb0",
            "1e94679bb62b470fab72517f10b21a61",
            "a11df72c58cb4fd2b3969fc6727da6f7"
          ]
        },
        "id": "wRtNiv8viEqO",
        "outputId": "a7b66e60-fa49-4b4b-8c64-d2325cbc6d79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c53705e166a422281340d3e8e4b590b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88c439241cd840f28c71e8674ab31799"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96e2a31c9de0457d91d288a0b0d26073"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4d08d78e96f4b58b682bb455a954026"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from LangPathModel.colab_src.nn import TrajectoryModel\n",
        "from LangPathModel.colab_src.textEncoders import TextEncoder\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "#data = [Batch, sequence, (batch input, batch target)]\n",
        "\n",
        "def train(model, dataloader, niter, device):\n",
        "    criterion = model.get_loss  # assumes it returns CrossEntropyLoss with ignore_index for padding\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "    Scheduler = StepLR(optimizer, step_size = 2, gamma=0.2)\n",
        "    model.positional_encoding = model.positional_encoding.to(device)\n",
        "    # The model is already defined outside the train function, no need to redefine it here\n",
        "    # model = TrajectoryModel()\n",
        "    model.train()\n",
        "    text_encoder = TextEncoder(output_dim=512)\n",
        "    text_encoder.to(device) # Move text_encoder to the device\n",
        "\n",
        "    for epoch in range(niter):\n",
        "        total_loss = 0\n",
        "        for batch_paths, batch_texts in dataloader:\n",
        "            #print(f\"paths: {batch_paths[0]}\")\n",
        "            batch_paths = batch_paths.to(device).float()\n",
        "            #print(type(batch_paths))\n",
        "            # Shift target for teacher forcing\n",
        "            decoder_input = batch_paths[:, :-1].to(device)      # all except last token, move to device\n",
        "            target_output = batch_paths[:, 1:].to(device)        # all except first token, move to device\n",
        "            encoder_input = batch_paths[:, 0].unsqueeze(1).to(device) # Move encoder_input to the device\n",
        "\n",
        "\n",
        "            encoder_input_mask = (encoder_input.abs().sum(dim=-1) != 0).int().reshape(-1, 1).to(device) # Move encoder_input_mask to the device\n",
        "            print(f\"encoder_input_mask: {encoder_input_mask.shape}\")\n",
        "            #print(f\"encoder_input: {encoder_input.shape}\"\n",
        "            emb_text = text_encoder(batch_texts['input_ids'].to(device), batch_texts['attention_mask'].to(device)) # Pass tensors on the device\n",
        "            text_mask = batch_texts['attention_mask'] == 0\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            #print(f\"encoder input mask: {encoder_input_mask.shape}\")\n",
        "            #print(f\"encoder_input: {encoder_input.shape}\")\n",
        "\n",
        "            emb_text = emb_text.to(device).float()\n",
        "            text_mask = text_mask.to(device).bool()\n",
        "\n",
        "            predictions = model(emb_text = emb_text, path = encoder_input, path_mask = encoder_input_mask, tgt = decoder_input, text_mask=text_mask)  # shape: [B, T]\n",
        "            # Reshape for loss: CrossEntropy wants [B*T, vocab_size] vs [B*T]\n",
        "\n",
        "            #predictions = predictions.reshape(-1, predictions.size(-1))\n",
        "            #print(\"predictions:\", predictions.shape)        # should be [32, 199, 512]\n",
        "            #print(\"target_output:\", target_output.shape)    # should be the same\n",
        "\n",
        "            loss = criterion(predictions, target_output)#fix this\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            print(loss.item())\n",
        "\n",
        "        Scheduler.step()\n",
        "        print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "id": "Dqb87axNiKK1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "_9Y52WdHnuB3",
        "outputId": "96f8db79-195d-4394-cefa-60d565750006"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 11, 512])\n",
            "combined mask: torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Expected key_padded_mask.shape[1] to be 11, but got 8",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-634b4d51e877>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         prediction = model(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0memb_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LangPathModel/colab_src/nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, path, emb_text, path_mask, tgt, text_mask)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m#print(emb_src.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m#print(f\"combined mask: {combined_mask.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    918\u001b[0m             x = self.norm1(\n\u001b[1;32m    919\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m             )\n\u001b[1;32m    922\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mis_causal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     ) -> Tensor:\n\u001b[0;32m--> 934\u001b[0;31m         x = self.self_attn(\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey_padding_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6340\u001b[0;31m             \u001b[0m_check_key_padding_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6342\u001b[0m         key_padding_mask = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_check_key_padding_mask\u001b[0;34m(key_padding_mask, src_len, bsz)\u001b[0m\n\u001b[1;32m   5987\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"Expected key_padded_mask.shape[0] to be {bsz}, but got {key_padding_mask.shape[0]}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5988\u001b[0m     )\n\u001b[0;32m-> 5989\u001b[0;31m     torch._check_with(\n\u001b[0m\u001b[1;32m   5990\u001b[0m         \u001b[0mAssertionError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5991\u001b[0m         \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_check_with\u001b[0;34m(error_type, cond, message)\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \u001b[0mmessage_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_evaluated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Expected key_padded_mask.shape[1] to be 11, but got 8"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from LangPathModel.colab_src.nn import TrajectoryModel\n",
        "\n",
        "from LangPathModel.colab_src.dataset_preprocessing import CirclePathDataset, collate_fn\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CirclePathDataset(\"/content/LangPathModel/data/circle_in_the middle.pt\")\n",
        "\n",
        "# Create a DataLoader with the custom collate_fn\n",
        "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "model = TrajectoryModel()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = model.to(device)\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.device}\")\n",
        "\n",
        "\n",
        "train(model = model, niter = 10, dataloader = dataloader, device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvuPsx8sk-65",
        "outputId": "bfb9480d-a93b-417b-babd-d2b691480c6c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "input_embedding.weight: cuda:0\n",
            "input_embedding.bias: cuda:0\n",
            "encoder.layers.0.self_attn.in_proj_weight: cuda:0\n",
            "encoder.layers.0.self_attn.in_proj_bias: cuda:0\n",
            "encoder.layers.0.self_attn.out_proj.weight: cuda:0\n",
            "encoder.layers.0.self_attn.out_proj.bias: cuda:0\n",
            "encoder.layers.0.linear1.weight: cuda:0\n",
            "encoder.layers.0.linear1.bias: cuda:0\n",
            "encoder.layers.0.linear2.weight: cuda:0\n",
            "encoder.layers.0.linear2.bias: cuda:0\n",
            "encoder.layers.0.norm1.weight: cuda:0\n",
            "encoder.layers.0.norm1.bias: cuda:0\n",
            "encoder.layers.0.norm2.weight: cuda:0\n",
            "encoder.layers.0.norm2.bias: cuda:0\n",
            "decoder.layers.0.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.0.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.0.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.0.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.0.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.0.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.0.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.0.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.0.linear1.weight: cuda:0\n",
            "decoder.layers.0.linear1.bias: cuda:0\n",
            "decoder.layers.0.linear2.weight: cuda:0\n",
            "decoder.layers.0.linear2.bias: cuda:0\n",
            "decoder.layers.0.norm1.weight: cuda:0\n",
            "decoder.layers.0.norm1.bias: cuda:0\n",
            "decoder.layers.0.norm2.weight: cuda:0\n",
            "decoder.layers.0.norm2.bias: cuda:0\n",
            "decoder.layers.0.norm3.weight: cuda:0\n",
            "decoder.layers.0.norm3.bias: cuda:0\n",
            "decoder.layers.1.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.1.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.1.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.1.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.1.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.1.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.1.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.1.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.1.linear1.weight: cuda:0\n",
            "decoder.layers.1.linear1.bias: cuda:0\n",
            "decoder.layers.1.linear2.weight: cuda:0\n",
            "decoder.layers.1.linear2.bias: cuda:0\n",
            "decoder.layers.1.norm1.weight: cuda:0\n",
            "decoder.layers.1.norm1.bias: cuda:0\n",
            "decoder.layers.1.norm2.weight: cuda:0\n",
            "decoder.layers.1.norm2.bias: cuda:0\n",
            "decoder.layers.1.norm3.weight: cuda:0\n",
            "decoder.layers.1.norm3.bias: cuda:0\n",
            "decoder.layers.2.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.2.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.2.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.2.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.2.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.2.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.2.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.2.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.2.linear1.weight: cuda:0\n",
            "decoder.layers.2.linear1.bias: cuda:0\n",
            "decoder.layers.2.linear2.weight: cuda:0\n",
            "decoder.layers.2.linear2.bias: cuda:0\n",
            "decoder.layers.2.norm1.weight: cuda:0\n",
            "decoder.layers.2.norm1.bias: cuda:0\n",
            "decoder.layers.2.norm2.weight: cuda:0\n",
            "decoder.layers.2.norm2.bias: cuda:0\n",
            "decoder.layers.2.norm3.weight: cuda:0\n",
            "decoder.layers.2.norm3.bias: cuda:0\n",
            "decoder.layers.3.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.3.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.3.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.3.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.3.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.3.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.3.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.3.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.3.linear1.weight: cuda:0\n",
            "decoder.layers.3.linear1.bias: cuda:0\n",
            "decoder.layers.3.linear2.weight: cuda:0\n",
            "decoder.layers.3.linear2.bias: cuda:0\n",
            "decoder.layers.3.norm1.weight: cuda:0\n",
            "decoder.layers.3.norm1.bias: cuda:0\n",
            "decoder.layers.3.norm2.weight: cuda:0\n",
            "decoder.layers.3.norm2.bias: cuda:0\n",
            "decoder.layers.3.norm3.weight: cuda:0\n",
            "decoder.layers.3.norm3.bias: cuda:0\n",
            "decoder.layers.4.self_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.4.self_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.4.self_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.4.self_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.4.multihead_attn.in_proj_weight: cuda:0\n",
            "decoder.layers.4.multihead_attn.in_proj_bias: cuda:0\n",
            "decoder.layers.4.multihead_attn.out_proj.weight: cuda:0\n",
            "decoder.layers.4.multihead_attn.out_proj.bias: cuda:0\n",
            "decoder.layers.4.linear1.weight: cuda:0\n",
            "decoder.layers.4.linear1.bias: cuda:0\n",
            "decoder.layers.4.linear2.weight: cuda:0\n",
            "decoder.layers.4.linear2.bias: cuda:0\n",
            "decoder.layers.4.norm1.weight: cuda:0\n",
            "decoder.layers.4.norm1.bias: cuda:0\n",
            "decoder.layers.4.norm2.weight: cuda:0\n",
            "decoder.layers.4.norm2.bias: cuda:0\n",
            "decoder.layers.4.norm3.weight: cuda:0\n",
            "decoder.layers.4.norm3.bias: cuda:0\n",
            "output_layer.weight: cuda:0\n",
            "output_layer.bias: cuda:0\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "127304.90625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "123499.8203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "120960.328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "118653.3046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "116534.953125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "114301.1015625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "111952.703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "109593.75\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "107160.4375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "104601.46875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "101956.140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "99254.9140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "96517.1484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "93732.203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "90824.21875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "87877.8203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "84863.3125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "81802.3984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "78697.71875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "75541.7109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "72358.890625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "69176.890625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "65959.0078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "62769.3046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "59520.1796875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "56304.125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "53079.63671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "49868.6640625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "46677.65625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "43584.3671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "40519.0703125\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "37551.9375\n",
            "Epoch 1 | Loss: 2703000.0898\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "34583.97265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "31720.0546875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "28967.302734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "26324.3671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "23775.0625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "21354.095703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "19055.884765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "16901.89453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "14896.5546875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "13040.5927734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "11335.1923828125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "9798.201171875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "8417.0322265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "7195.0263671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "6137.0302734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "5232.3037109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "4466.54638671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3855.083251953125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3369.524658203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3005.31298828125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2756.2783203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2593.762939453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2514.97998046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2502.609130859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2541.184326171875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2617.70361328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2716.55078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2827.86669921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2939.448486328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3043.491455078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3134.591796875\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "3206.924072265625\n",
            "Epoch 2 | Loss: 326826.4272\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3251.41552734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3257.318359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3252.25927734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3252.30859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3239.557861328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3224.968017578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3206.91650390625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3187.81494140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3163.83447265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3135.033203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3103.529541015625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3066.337158203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "3030.318115234375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2990.583740234375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2947.448486328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2902.733642578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2861.163330078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2813.22607421875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2764.663818359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2720.12744140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2675.236083984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2632.8681640625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2596.1640625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2563.253662109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2537.296142578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2518.1884765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2505.932861328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2501.19384765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2502.656982421875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2509.126708984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2518.60009765625\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2529.6923828125\n",
            "Epoch 3 | Loss: 91961.7676\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2537.22509765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2542.564208984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2546.13623046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2546.2119140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2541.985107421875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2535.846923828125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2528.6591796875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2521.49658203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2515.320068359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2509.913818359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2505.990478515625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2502.94677734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2501.14013671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.491455078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.803466796875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2501.47509765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2502.5234375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2503.46533203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2504.460693359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2505.42333984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2505.97314453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2506.49755859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2506.262451171875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2505.7646484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2505.158203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2504.419921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2503.939453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2503.14453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2502.484619140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2501.678955078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2501.06298828125\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2500.651123046875\n",
            "Epoch 4 | Loss: 80401.1169\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.37158203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.24609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.302734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.3310546875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.24267578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.22607421875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.218994140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.251953125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.26123046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.16162109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1845703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.168212890625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1904296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.137939453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1943359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.18994140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.176513671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.164794921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.21044921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.18359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.163330078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09228515625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.178955078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.2109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.164306640625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.214599609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1943359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.17919921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.18505859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.20849609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.177001953125\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2500.25048828125\n",
            "Epoch 5 | Loss: 80006.6338\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.142578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1787109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.188720703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.089111328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.111083984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.152099609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.140380859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.156005859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.094970703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.22509765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.137939453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11376953125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.155029296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.14453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.152099609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0947265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1162109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.141357421875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.182861328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.133544921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.12060546875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.138427734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.107666015625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11474609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.080322265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.12646484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.101318359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.102783203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.12255859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.118896484375\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2500.181396484375\n",
            "Epoch 6 | Loss: 80004.2793\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1044921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.101318359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0908203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.10400390625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09033203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09033203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.118896484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09521484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09423828125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11474609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.13720703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.097412109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.10986328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.141845703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.123779296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.136474609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.110595703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.130126953125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.076171875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11376953125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11767578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.117919921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.12158203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.10302734375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08544921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.053955078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.102783203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.088134765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08251953125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.093994140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.087890625\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2500.0546875\n",
            "Epoch 7 | Loss: 80003.2913\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.10009765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.120361328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.099609375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08642578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1123046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.12744140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.092529296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.108642578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.074951171875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.119384765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.084716796875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.087158203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.093505859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.088623046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.072509765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1171875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.07763671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.121826171875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11865234375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.117919921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0771484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.103515625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.080078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11669921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08154296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.072509765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.099853515625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.059814453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.062255859375\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2500.12744140625\n",
            "Epoch 8 | Loss: 80003.1172\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.092041015625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.062744140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.07470703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.092529296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.088623046875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09423828125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.096435546875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.10888671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0986328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09033203125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0771484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.084716796875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.111572265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.092041015625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.103271484375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.07763671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08544921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1064453125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.06005859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.078857421875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0869140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1220703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.077392578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.080078125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.103515625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.06884765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.10986328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.093505859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11083984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.12255859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11328125\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2500.06005859375\n",
            "Epoch 9 | Loss: 80002.9253\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0810546875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.082763671875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0986328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.089111328125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.094970703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.093505859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09619140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11865234375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.079833984375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.1005859375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.093994140625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.097900390625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.0810546875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.083740234375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.109375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.097900390625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11669921875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.09423828125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.07568359375\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.07275390625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.053466796875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08447265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.08154296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.093017578125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.095947265625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.088134765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.11279296875\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.110595703125\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.072509765625\n",
            "encoder_input_mask: torch.Size([32, 1])\n",
            "torch.Size([32, 5, 512])\n",
            "combined mask: torch.Size([32, 5])\n",
            "2500.05908203125\n",
            "encoder_input_mask: torch.Size([8, 1])\n",
            "torch.Size([8, 5, 512])\n",
            "combined mask: torch.Size([8, 5])\n",
            "2500.1162109375\n",
            "Epoch 10 | Loss: 80002.9202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "import numpy as np\n",
        "from LangPathModel.colab_src.textEncoders import TextEncoder\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer and encoder\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "text_encoder = TextEncoder(output_dim=512)\n",
        "\n",
        "# Text and encoding\n",
        "text = \"Draw circle in the middle\"\n",
        "encoded = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "txt = text_encoder(encoded['input_ids'], encoded['attention_mask'])\n",
        "\n",
        "# Setup device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "txt = txt.to(device)\n",
        "txt_mask = (encoded['attention_mask'] == 0).to(device)\n",
        "\n",
        "path_mask = torch.Tensor([[1]]).to(device)\n",
        "\n",
        "# Iniptialize starting point\n",
        "start = torch.Tensor([[[100, 100, 0, 0]]]).to(device)  # (1, 1, 4)\n",
        "tgt = torch.empty([1, 1, 4]).to(device)  # (1, 1, 4)\n",
        "\n",
        "# Store predictions\n",
        "positions = []\n",
        "\n",
        "# Loop to generate 100 predictions\n",
        "for i in range(20):\n",
        "    with torch.no_grad():\n",
        "        prediction = model(\n",
        "            emb_text=txt,\n",
        "            path=start,\n",
        "            tgt=tgt,\n",
        "            text_mask=txt_mask,\n",
        "            path_mask=path_mask\n",
        "        )  # Output shape: (1, seq_len+1, 4\n",
        "    next_point = prediction[:, -1, :]  # Get the last predicted point\n",
        "    print(prediction)\n",
        "    positions.append(next_point[0, :2].cpu().numpy())  # Save (x, y)\n",
        "\n",
        "    # Append next_point to tgt for next prediction\n",
        "    tgt = torch.cat([tgt, next_point.unsqueeze(1)], dim=1)\n",
        "\n",
        "# Convert to numpy array\n",
        "positions = np.array(positions)  # shape: (num_points, 2)\n",
        "colors = np.linspace(0, 1, len(positions))  # Normalized color values for time\n",
        "\n",
        "# Scatter plot with color based on time\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(positions[:, 0], positions[:, 1], c=colors, cmap='plasma', s=50)\n",
        "plt.colorbar(label=\"Time Step\")\n",
        "plt.title(\"Generated Path with Time-Colored Scatter\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CogZFHWAq695",
        "outputId": "e52675b9-36ea-4d05-d086-24e04c87c599"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9092e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03]]], device='cuda:0')\n",
            "torch.Size([1, 8, 512])\n",
            "combined mask: torch.Size([1, 8])\n",
            "tensor([[[4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9096e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9093e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9094e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9095e-03],\n",
            "         [4.9960e+02, 5.0043e+02, 9.4417e-01, 6.9091e-03]]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}